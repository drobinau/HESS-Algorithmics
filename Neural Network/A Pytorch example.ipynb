{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  loss:  0.2607240080833435\n",
      "epoch:  1  loss:  0.2605815827846527\n",
      "epoch:  2  loss:  0.260439395904541\n",
      "epoch:  3  loss:  0.2602974772453308\n",
      "epoch:  4  loss:  0.2601557672023773\n",
      "epoch:  5  loss:  0.2600143551826477\n",
      "epoch:  6  loss:  0.2598731517791748\n",
      "epoch:  7  loss:  0.2597322165966034\n",
      "epoch:  8  loss:  0.25959154963493347\n",
      "epoch:  9  loss:  0.25945109128952026\n",
      "epoch:  10  loss:  0.25931087136268616\n",
      "epoch:  11  loss:  0.25917088985443115\n",
      "epoch:  12  loss:  0.2590312063694\n",
      "epoch:  13  loss:  0.25889167189598083\n",
      "epoch:  14  loss:  0.25875240564346313\n",
      "epoch:  15  loss:  0.2586134076118469\n",
      "epoch:  16  loss:  0.2584746479988098\n",
      "epoch:  17  loss:  0.25833606719970703\n",
      "epoch:  18  loss:  0.25820478796958923\n",
      "epoch:  19  loss:  0.258076548576355\n",
      "epoch:  20  loss:  0.25794848799705505\n",
      "epoch:  21  loss:  0.25782063603401184\n",
      "epoch:  22  loss:  0.25769299268722534\n",
      "epoch:  23  loss:  0.25756561756134033\n",
      "epoch:  24  loss:  0.25743845105171204\n",
      "epoch:  25  loss:  0.25731146335601807\n",
      "epoch:  26  loss:  0.2571847140789032\n",
      "epoch:  27  loss:  0.2570580840110779\n",
      "epoch:  28  loss:  0.25693175196647644\n",
      "epoch:  29  loss:  0.2568056285381317\n",
      "epoch:  30  loss:  0.2566796839237213\n",
      "epoch:  31  loss:  0.2565539479255676\n",
      "epoch:  32  loss:  0.25642842054367065\n",
      "epoch:  33  loss:  0.256303071975708\n",
      "epoch:  34  loss:  0.25617796182632446\n",
      "epoch:  35  loss:  0.25605300068855286\n",
      "epoch:  36  loss:  0.2559282183647156\n",
      "epoch:  37  loss:  0.2558037042617798\n",
      "epoch:  38  loss:  0.25567930936813354\n",
      "epoch:  39  loss:  0.2555552124977112\n",
      "epoch:  40  loss:  0.255431205034256\n",
      "epoch:  41  loss:  0.2553074061870575\n",
      "epoch:  42  loss:  0.2551838755607605\n",
      "epoch:  43  loss:  0.2550604045391083\n",
      "epoch:  44  loss:  0.25493723154067993\n",
      "epoch:  45  loss:  0.25481414794921875\n",
      "epoch:  46  loss:  0.25469130277633667\n",
      "epoch:  47  loss:  0.25456860661506653\n",
      "epoch:  48  loss:  0.2544460892677307\n",
      "epoch:  49  loss:  0.2543237805366516\n",
      "epoch:  50  loss:  0.25420162081718445\n",
      "epoch:  51  loss:  0.2540796399116516\n",
      "epoch:  52  loss:  0.2539578378200531\n",
      "epoch:  53  loss:  0.2538362145423889\n",
      "epoch:  54  loss:  0.25371474027633667\n",
      "epoch:  55  loss:  0.25359347462654114\n",
      "epoch:  56  loss:  0.25347238779067993\n",
      "epoch:  57  loss:  0.25335144996643066\n",
      "epoch:  58  loss:  0.25323063135147095\n",
      "epoch:  59  loss:  0.25311002135276794\n",
      "epoch:  60  loss:  0.25298959016799927\n",
      "epoch:  61  loss:  0.25286921858787537\n",
      "epoch:  62  loss:  0.25274914503097534\n",
      "epoch:  63  loss:  0.2526291608810425\n",
      "epoch:  64  loss:  0.25250935554504395\n",
      "epoch:  65  loss:  0.25238966941833496\n",
      "epoch:  66  loss:  0.2522701919078827\n",
      "epoch:  67  loss:  0.25215083360671997\n",
      "epoch:  68  loss:  0.2520316541194916\n",
      "epoch:  69  loss:  0.25191259384155273\n",
      "epoch:  70  loss:  0.2517937123775482\n",
      "epoch:  71  loss:  0.25167495012283325\n",
      "epoch:  72  loss:  0.2515563368797302\n",
      "epoch:  73  loss:  0.25143787264823914\n",
      "epoch:  74  loss:  0.25131961703300476\n",
      "epoch:  75  loss:  0.25120145082473755\n",
      "epoch:  76  loss:  0.2510834336280823\n",
      "epoch:  77  loss:  0.25096553564071655\n",
      "epoch:  78  loss:  0.25084781646728516\n",
      "epoch:  79  loss:  0.2507302165031433\n",
      "epoch:  80  loss:  0.2506127655506134\n",
      "epoch:  81  loss:  0.25049543380737305\n",
      "epoch:  82  loss:  0.25037819147109985\n",
      "epoch:  83  loss:  0.25026118755340576\n",
      "epoch:  84  loss:  0.25014427304267883\n",
      "epoch:  85  loss:  0.25002747774124146\n",
      "epoch:  86  loss:  0.24991083145141602\n",
      "epoch:  87  loss:  0.24979427456855774\n",
      "epoch:  88  loss:  0.2496778666973114\n",
      "epoch:  89  loss:  0.2495616376399994\n",
      "epoch:  90  loss:  0.24944548308849335\n",
      "epoch:  91  loss:  0.24932944774627686\n",
      "epoch:  92  loss:  0.2492135465145111\n",
      "epoch:  93  loss:  0.2490977793931961\n",
      "epoch:  94  loss:  0.24898210167884827\n",
      "epoch:  95  loss:  0.24886658787727356\n",
      "epoch:  96  loss:  0.24875116348266602\n",
      "epoch:  97  loss:  0.24863585829734802\n",
      "epoch:  98  loss:  0.24852068722248077\n",
      "epoch:  99  loss:  0.24840562045574188\n",
      "epoch:  100  loss:  0.24829065799713135\n",
      "epoch:  101  loss:  0.24817581474781036\n",
      "epoch:  102  loss:  0.24806106090545654\n",
      "epoch:  103  loss:  0.24794645607471466\n",
      "epoch:  104  loss:  0.24783197045326233\n",
      "epoch:  105  loss:  0.24771757423877716\n",
      "epoch:  106  loss:  0.24760334193706512\n",
      "epoch:  107  loss:  0.24748918414115906\n",
      "epoch:  108  loss:  0.24737520515918732\n",
      "epoch:  109  loss:  0.24726125597953796\n",
      "epoch:  110  loss:  0.24714747071266174\n",
      "epoch:  111  loss:  0.2470337599515915\n",
      "epoch:  112  loss:  0.24692018330097198\n",
      "epoch:  113  loss:  0.24680669605731964\n",
      "epoch:  114  loss:  0.24669328331947327\n",
      "epoch:  115  loss:  0.24658000469207764\n",
      "epoch:  116  loss:  0.24646680057048798\n",
      "epoch:  117  loss:  0.24635370075702667\n",
      "epoch:  118  loss:  0.24624066054821014\n",
      "epoch:  119  loss:  0.24612776935100555\n",
      "epoch:  120  loss:  0.24601492285728455\n",
      "epoch:  121  loss:  0.24590222537517548\n",
      "epoch:  122  loss:  0.24578957259655\n",
      "epoch:  123  loss:  0.24567702412605286\n",
      "epoch:  124  loss:  0.24556457996368408\n",
      "epoch:  125  loss:  0.24545221030712128\n",
      "epoch:  126  loss:  0.24533991515636444\n",
      "epoch:  127  loss:  0.24522772431373596\n",
      "epoch:  128  loss:  0.24511556327342987\n",
      "epoch:  129  loss:  0.2450036108493805\n",
      "epoch:  130  loss:  0.24489164352416992\n",
      "epoch:  131  loss:  0.2447797954082489\n",
      "epoch:  132  loss:  0.24466797709465027\n",
      "epoch:  133  loss:  0.24455630779266357\n",
      "epoch:  134  loss:  0.24444468319416046\n",
      "epoch:  135  loss:  0.24433310329914093\n",
      "epoch:  136  loss:  0.24422164261341095\n",
      "epoch:  137  loss:  0.24411027133464813\n",
      "epoch:  138  loss:  0.2439989149570465\n",
      "epoch:  139  loss:  0.24388766288757324\n",
      "epoch:  140  loss:  0.24377651512622833\n",
      "epoch:  141  loss:  0.243665412068367\n",
      "epoch:  142  loss:  0.24355439841747284\n",
      "epoch:  143  loss:  0.24344341456890106\n",
      "epoch:  144  loss:  0.24333254992961884\n",
      "epoch:  145  loss:  0.2432216852903366\n",
      "epoch:  146  loss:  0.24311096966266632\n",
      "epoch:  147  loss:  0.24300023913383484\n",
      "epoch:  148  loss:  0.2428896427154541\n",
      "epoch:  149  loss:  0.24277909100055695\n",
      "epoch:  150  loss:  0.24266858398914337\n",
      "epoch:  151  loss:  0.24255812168121338\n",
      "epoch:  152  loss:  0.24244773387908936\n",
      "epoch:  153  loss:  0.2423374354839325\n",
      "epoch:  154  loss:  0.2422271966934204\n",
      "epoch:  155  loss:  0.2421170026063919\n",
      "epoch:  156  loss:  0.24200685322284698\n",
      "epoch:  157  loss:  0.24189677834510803\n",
      "epoch:  158  loss:  0.24178676307201385\n",
      "epoch:  159  loss:  0.24167677760124207\n",
      "epoch:  160  loss:  0.24156685173511505\n",
      "epoch:  161  loss:  0.2414570152759552\n",
      "epoch:  162  loss:  0.24134716391563416\n",
      "epoch:  163  loss:  0.24123744666576385\n",
      "epoch:  164  loss:  0.24112772941589355\n",
      "epoch:  165  loss:  0.24101802706718445\n",
      "epoch:  166  loss:  0.2409084290266037\n",
      "epoch:  167  loss:  0.24079887568950653\n",
      "epoch:  168  loss:  0.24068932235240936\n",
      "epoch:  169  loss:  0.24057987332344055\n",
      "epoch:  170  loss:  0.24047043919563293\n",
      "epoch:  171  loss:  0.2403610646724701\n",
      "epoch:  172  loss:  0.24025170505046844\n",
      "epoch:  173  loss:  0.24014241993427277\n",
      "epoch:  174  loss:  0.24003314971923828\n",
      "epoch:  175  loss:  0.23992395401000977\n",
      "epoch:  176  loss:  0.23981475830078125\n",
      "epoch:  177  loss:  0.23970560729503632\n",
      "epoch:  178  loss:  0.23959651589393616\n",
      "epoch:  179  loss:  0.2394874393939972\n",
      "epoch:  180  loss:  0.239378422498703\n",
      "epoch:  181  loss:  0.23926942050457\n",
      "epoch:  182  loss:  0.23916049301624298\n",
      "epoch:  183  loss:  0.23905155062675476\n",
      "epoch:  184  loss:  0.23894266784191132\n",
      "epoch:  185  loss:  0.23883378505706787\n",
      "epoch:  186  loss:  0.2387249767780304\n",
      "epoch:  187  loss:  0.23861615359783173\n",
      "epoch:  188  loss:  0.23850739002227783\n",
      "epoch:  189  loss:  0.23839867115020752\n",
      "epoch:  190  loss:  0.2382899522781372\n",
      "epoch:  191  loss:  0.23818126320838928\n",
      "epoch:  192  loss:  0.23807258903980255\n",
      "epoch:  193  loss:  0.2379639893770218\n",
      "epoch:  194  loss:  0.23785535991191864\n",
      "epoch:  195  loss:  0.2377472221851349\n",
      "epoch:  196  loss:  0.23764197528362274\n",
      "epoch:  197  loss:  0.23753675818443298\n",
      "epoch:  198  loss:  0.23743149638175964\n",
      "epoch:  199  loss:  0.2373262345790863\n",
      "epoch:  200  loss:  0.23722104728221893\n",
      "epoch:  201  loss:  0.2371157854795456\n",
      "epoch:  202  loss:  0.23701052367687225\n",
      "epoch:  203  loss:  0.2369052916765213\n",
      "epoch:  204  loss:  0.23680002987384796\n",
      "epoch:  205  loss:  0.23669476807117462\n",
      "epoch:  206  loss:  0.23658950626850128\n",
      "epoch:  207  loss:  0.23648421466350555\n",
      "epoch:  208  loss:  0.23637895286083221\n",
      "epoch:  209  loss:  0.23627367615699768\n",
      "epoch:  210  loss:  0.23616835474967957\n",
      "epoch:  211  loss:  0.23606309294700623\n",
      "epoch:  212  loss:  0.2359577715396881\n",
      "epoch:  213  loss:  0.23585245013237\n",
      "epoch:  214  loss:  0.23574712872505188\n",
      "epoch:  215  loss:  0.23564179241657257\n",
      "epoch:  216  loss:  0.23553641140460968\n",
      "epoch:  217  loss:  0.23543107509613037\n",
      "epoch:  218  loss:  0.23532569408416748\n",
      "epoch:  219  loss:  0.2352203130722046\n",
      "epoch:  220  loss:  0.2351149320602417\n",
      "epoch:  221  loss:  0.23500952124595642\n",
      "epoch:  222  loss:  0.23490409553050995\n",
      "epoch:  223  loss:  0.23479866981506348\n",
      "epoch:  224  loss:  0.23469319939613342\n",
      "epoch:  225  loss:  0.23458771407604218\n",
      "epoch:  226  loss:  0.23448221385478973\n",
      "epoch:  227  loss:  0.2343767136335373\n",
      "epoch:  228  loss:  0.23427119851112366\n",
      "epoch:  229  loss:  0.23416562378406525\n",
      "epoch:  230  loss:  0.23406007885932922\n",
      "epoch:  231  loss:  0.233954519033432\n",
      "epoch:  232  loss:  0.23384888470172882\n",
      "epoch:  233  loss:  0.23374326527118683\n",
      "epoch:  234  loss:  0.23363761603832245\n",
      "epoch:  235  loss:  0.23353195190429688\n",
      "epoch:  236  loss:  0.2334262877702713\n",
      "epoch:  237  loss:  0.23332056403160095\n",
      "epoch:  238  loss:  0.2332148253917694\n",
      "epoch:  239  loss:  0.23310908675193787\n",
      "epoch:  240  loss:  0.23300328850746155\n",
      "epoch:  241  loss:  0.23289747536182404\n",
      "epoch:  242  loss:  0.23279163241386414\n",
      "epoch:  243  loss:  0.23268577456474304\n",
      "epoch:  244  loss:  0.23257987201213837\n",
      "epoch:  245  loss:  0.2324739694595337\n",
      "epoch:  246  loss:  0.23236803710460663\n",
      "epoch:  247  loss:  0.23226208984851837\n",
      "epoch:  248  loss:  0.23215708136558533\n",
      "epoch:  249  loss:  0.23205439746379852\n",
      "epoch:  250  loss:  0.2319483458995819\n",
      "epoch:  251  loss:  0.2318456470966339\n",
      "epoch:  252  loss:  0.23174062371253967\n",
      "epoch:  253  loss:  0.23163583874702454\n",
      "epoch:  254  loss:  0.23153285682201385\n",
      "epoch:  255  loss:  0.23142671585083008\n",
      "epoch:  256  loss:  0.23132427036762238\n",
      "epoch:  257  loss:  0.2312188446521759\n",
      "epoch:  258  loss:  0.23111429810523987\n",
      "epoch:  259  loss:  0.23101095855236053\n",
      "epoch:  260  loss:  0.23090466856956482\n",
      "epoch:  261  loss:  0.23080261051654816\n",
      "epoch:  262  loss:  0.2306966781616211\n",
      "epoch:  263  loss:  0.2305925339460373\n",
      "epoch:  264  loss:  0.23048865795135498\n",
      "epoch:  265  loss:  0.23038236796855927\n",
      "epoch:  266  loss:  0.23028051853179932\n",
      "epoch:  267  loss:  0.23017406463623047\n",
      "epoch:  268  loss:  0.23007044196128845\n",
      "epoch:  269  loss:  0.22996583580970764\n",
      "epoch:  270  loss:  0.22986015677452087\n",
      "epoch:  271  loss:  0.22975754737854004\n",
      "epoch:  272  loss:  0.22965097427368164\n",
      "epoch:  273  loss:  0.22954797744750977\n",
      "epoch:  274  loss:  0.2294425517320633\n",
      "epoch:  275  loss:  0.22933749854564667\n",
      "epoch:  276  loss:  0.22923406958580017\n",
      "epoch:  277  loss:  0.22912731766700745\n",
      "epoch:  278  loss:  0.22902512550354004\n",
      "epoch:  279  loss:  0.2289186716079712\n",
      "epoch:  280  loss:  0.22881445288658142\n",
      "epoch:  281  loss:  0.22870998084545135\n",
      "epoch:  282  loss:  0.22860369086265564\n",
      "epoch:  283  loss:  0.22850120067596436\n",
      "epoch:  284  loss:  0.22839419543743134\n",
      "epoch:  285  loss:  0.22829094529151917\n",
      "epoch:  286  loss:  0.22818529605865479\n",
      "epoch:  287  loss:  0.22807995975017548\n",
      "epoch:  288  loss:  0.22797627747058868\n",
      "epoch:  289  loss:  0.22786907851696014\n",
      "epoch:  290  loss:  0.22776691615581512\n",
      "epoch:  291  loss:  0.2276599109172821\n",
      "epoch:  292  loss:  0.22755572199821472\n",
      "epoch:  293  loss:  0.22745060920715332\n",
      "epoch:  294  loss:  0.22734439373016357\n",
      "epoch:  295  loss:  0.22724124789237976\n",
      "epoch:  296  loss:  0.22713379561901093\n",
      "epoch:  297  loss:  0.2270309180021286\n",
      "epoch:  298  loss:  0.22692427039146423\n",
      "epoch:  299  loss:  0.22681936621665955\n",
      "epoch:  300  loss:  0.2267146110534668\n",
      "epoch:  301  loss:  0.22660771012306213\n",
      "epoch:  302  loss:  0.226504847407341\n",
      "epoch:  303  loss:  0.22639712691307068\n",
      "epoch:  304  loss:  0.22629372775554657\n",
      "epoch:  305  loss:  0.22618718445301056\n",
      "epoch:  306  loss:  0.22608180344104767\n",
      "epoch:  307  loss:  0.2259771078824997\n",
      "epoch:  308  loss:  0.22586973011493683\n",
      "epoch:  309  loss:  0.22576694190502167\n",
      "epoch:  310  loss:  0.22565893828868866\n",
      "epoch:  311  loss:  0.22555527091026306\n",
      "epoch:  312  loss:  0.22544856369495392\n",
      "epoch:  313  loss:  0.22534291446208954\n",
      "epoch:  314  loss:  0.22523804008960724\n",
      "epoch:  315  loss:  0.22513046860694885\n",
      "epoch:  316  loss:  0.2250274121761322\n",
      "epoch:  317  loss:  0.22491911053657532\n",
      "epoch:  318  loss:  0.2248154580593109\n",
      "epoch:  319  loss:  0.22470828890800476\n",
      "epoch:  320  loss:  0.22460265457630157\n",
      "epoch:  321  loss:  0.22449728846549988\n",
      "epoch:  322  loss:  0.22438976168632507\n",
      "epoch:  323  loss:  0.22428619861602783\n",
      "epoch:  324  loss:  0.2241775542497635\n",
      "epoch:  325  loss:  0.224074125289917\n",
      "epoch:  326  loss:  0.22396621108055115\n",
      "epoch:  327  loss:  0.2238609343767166\n",
      "epoch:  328  loss:  0.22375479340553284\n",
      "epoch:  329  loss:  0.22364754974842072\n",
      "epoch:  330  loss:  0.2235431671142578\n",
      "epoch:  331  loss:  0.223434180021286\n",
      "epoch:  332  loss:  0.22333133220672607\n",
      "epoch:  333  loss:  0.22322234511375427\n",
      "epoch:  334  loss:  0.2231176346540451\n",
      "epoch:  335  loss:  0.22301042079925537\n",
      "epoch:  336  loss:  0.2229038029909134\n",
      "epoch:  337  loss:  0.22279831767082214\n",
      "epoch:  338  loss:  0.22268982231616974\n",
      "epoch:  339  loss:  0.22258606553077698\n",
      "epoch:  340  loss:  0.22247660160064697\n",
      "epoch:  341  loss:  0.22237277030944824\n",
      "epoch:  342  loss:  0.2222640961408615\n",
      "epoch:  343  loss:  0.22215846180915833\n",
      "epoch:  344  loss:  0.22205142676830292\n",
      "epoch:  345  loss:  0.22194400429725647\n",
      "epoch:  346  loss:  0.22183866798877716\n",
      "epoch:  347  loss:  0.22172939777374268\n",
      "epoch:  348  loss:  0.22162571549415588\n",
      "epoch:  349  loss:  0.22151580452919006\n",
      "epoch:  350  loss:  0.22141143679618835\n",
      "epoch:  351  loss:  0.2213025540113449\n",
      "epoch:  352  loss:  0.2211964875459671\n",
      "epoch:  353  loss:  0.2210891991853714\n",
      "epoch:  354  loss:  0.22098132967948914\n",
      "epoch:  355  loss:  0.22087566554546356\n",
      "epoch:  356  loss:  0.2207660675048828\n",
      "epoch:  357  loss:  0.2206619679927826\n",
      "epoch:  358  loss:  0.22055156528949738\n",
      "epoch:  359  loss:  0.22044721245765686\n",
      "epoch:  360  loss:  0.22033759951591492\n",
      "epoch:  361  loss:  0.2202315628528595\n",
      "epoch:  362  loss:  0.2201234996318817\n",
      "epoch:  363  loss:  0.2200157344341278\n",
      "epoch:  364  loss:  0.21990922093391418\n",
      "epoch:  365  loss:  0.21979978680610657\n",
      "epoch:  366  loss:  0.21969476342201233\n",
      "epoch:  367  loss:  0.21958383917808533\n",
      "epoch:  368  loss:  0.2194799929857254\n",
      "epoch:  369  loss:  0.2193690985441208\n",
      "epoch:  370  loss:  0.21926362812519073\n",
      "epoch:  371  loss:  0.2191542387008667\n",
      "epoch:  372  loss:  0.21904711425304413\n",
      "epoch:  373  loss:  0.2189391851425171\n",
      "epoch:  374  loss:  0.2188304364681244\n",
      "epoch:  375  loss:  0.21872393786907196\n",
      "epoch:  376  loss:  0.2186136245727539\n",
      "epoch:  377  loss:  0.2185085564851761\n",
      "epoch:  378  loss:  0.21839694678783417\n",
      "epoch:  379  loss:  0.21829259395599365\n",
      "epoch:  380  loss:  0.2181812822818756\n",
      "epoch:  381  loss:  0.21807536482810974\n",
      "epoch:  382  loss:  0.21796543896198273\n",
      "epoch:  383  loss:  0.21785800158977509\n",
      "epoch:  384  loss:  0.21774940192699432\n",
      "epoch:  385  loss:  0.21764042973518372\n",
      "epoch:  386  loss:  0.2175331860780716\n",
      "epoch:  387  loss:  0.2174226939678192\n",
      "epoch:  388  loss:  0.21731679141521454\n",
      "epoch:  389  loss:  0.21720480918884277\n",
      "epoch:  390  loss:  0.21710018813610077\n",
      "epoch:  391  loss:  0.21698784828186035\n",
      "epoch:  392  loss:  0.2168823927640915\n",
      "epoch:  393  loss:  0.2167709767818451\n",
      "epoch:  394  loss:  0.21666410565376282\n",
      "epoch:  395  loss:  0.2165539264678955\n",
      "epoch:  396  loss:  0.21644563972949982\n",
      "epoch:  397  loss:  0.2163366973400116\n",
      "epoch:  398  loss:  0.21622700989246368\n",
      "epoch:  399  loss:  0.21611931920051575\n",
      "epoch:  400  loss:  0.21600821614265442\n",
      "epoch:  401  loss:  0.2159017026424408\n",
      "epoch:  402  loss:  0.21578927338123322\n",
      "epoch:  403  loss:  0.2156839370727539\n",
      "epoch:  404  loss:  0.21557077765464783\n",
      "epoch:  405  loss:  0.21546533703804016\n",
      "epoch:  406  loss:  0.21535268425941467\n",
      "epoch:  407  loss:  0.21524599194526672\n",
      "epoch:  408  loss:  0.2151344269514084\n",
      "epoch:  409  loss:  0.21502640843391418\n",
      "epoch:  410  loss:  0.21491599082946777\n",
      "epoch:  411  loss:  0.21480675041675568\n",
      "epoch:  412  loss:  0.21469751000404358\n",
      "epoch:  413  loss:  0.21458733081817627\n",
      "epoch:  414  loss:  0.21447935700416565\n",
      "epoch:  415  loss:  0.21436795592308044\n",
      "epoch:  416  loss:  0.21426038444042206\n",
      "epoch:  417  loss:  0.21413569152355194\n",
      "epoch:  418  loss:  0.21401770412921906\n",
      "epoch:  419  loss:  0.213891863822937\n",
      "epoch:  420  loss:  0.2137749195098877\n",
      "epoch:  421  loss:  0.2136489897966385\n",
      "epoch:  422  loss:  0.2135309875011444\n",
      "epoch:  423  loss:  0.21340599656105042\n",
      "epoch:  424  loss:  0.21328690648078918\n",
      "epoch:  425  loss:  0.2131628692150116\n",
      "epoch:  426  loss:  0.2130427360534668\n",
      "epoch:  427  loss:  0.21291962265968323\n",
      "epoch:  428  loss:  0.21279847621917725\n",
      "epoch:  429  loss:  0.2126762419939041\n",
      "epoch:  430  loss:  0.21255406737327576\n",
      "epoch:  431  loss:  0.21243277192115784\n",
      "epoch:  432  loss:  0.2123095691204071\n",
      "epoch:  433  loss:  0.21218912303447723\n",
      "epoch:  434  loss:  0.2120649814605713\n",
      "epoch:  435  loss:  0.21194538474082947\n",
      "epoch:  436  loss:  0.21182028949260712\n",
      "epoch:  437  loss:  0.21170146763324738\n",
      "epoch:  438  loss:  0.2115754783153534\n",
      "epoch:  439  loss:  0.21145744621753693\n",
      "epoch:  440  loss:  0.2113305777311325\n",
      "epoch:  441  loss:  0.21121326088905334\n",
      "epoch:  442  loss:  0.21108630299568176\n",
      "epoch:  443  loss:  0.21096818149089813\n",
      "epoch:  444  loss:  0.21084192395210266\n",
      "epoch:  445  loss:  0.21072295308113098\n",
      "epoch:  446  loss:  0.21059736609458923\n",
      "epoch:  447  loss:  0.21047762036323547\n",
      "epoch:  448  loss:  0.21035270392894745\n",
      "epoch:  449  loss:  0.21023216843605042\n",
      "epoch:  450  loss:  0.21010784804821014\n",
      "epoch:  451  loss:  0.209986612200737\n",
      "epoch:  452  loss:  0.20986290276050568\n",
      "epoch:  453  loss:  0.20974095165729523\n",
      "epoch:  454  loss:  0.20961780846118927\n",
      "epoch:  455  loss:  0.2094951570034027\n",
      "epoch:  456  loss:  0.20937256515026093\n",
      "epoch:  457  loss:  0.20924921333789825\n",
      "epoch:  458  loss:  0.20912718772888184\n",
      "epoch:  459  loss:  0.20900316536426544\n",
      "epoch:  460  loss:  0.20888161659240723\n",
      "epoch:  461  loss:  0.20875701308250427\n",
      "epoch:  462  loss:  0.20863589644432068\n",
      "epoch:  463  loss:  0.20851075649261475\n",
      "epoch:  464  loss:  0.2083900421857834\n",
      "epoch:  465  loss:  0.2082643061876297\n",
      "epoch:  466  loss:  0.20814403891563416\n",
      "epoch:  467  loss:  0.20801779627799988\n",
      "epoch:  468  loss:  0.2078978717327118\n",
      "epoch:  469  loss:  0.20777110755443573\n",
      "epoch:  470  loss:  0.20765157043933868\n",
      "epoch:  471  loss:  0.2075243443250656\n",
      "epoch:  472  loss:  0.20740509033203125\n",
      "epoch:  473  loss:  0.20727744698524475\n",
      "epoch:  474  loss:  0.20715844631195068\n",
      "epoch:  475  loss:  0.20703038573265076\n",
      "epoch:  476  loss:  0.20691165328025818\n",
      "epoch:  477  loss:  0.2067832499742508\n",
      "epoch:  478  loss:  0.20666471123695374\n",
      "epoch:  479  loss:  0.2065359354019165\n",
      "epoch:  480  loss:  0.20641759037971497\n",
      "epoch:  481  loss:  0.20628850162029266\n",
      "epoch:  482  loss:  0.20617032051086426\n",
      "epoch:  483  loss:  0.20604100823402405\n",
      "epoch:  484  loss:  0.20592279732227325\n",
      "epoch:  485  loss:  0.20579347014427185\n",
      "epoch:  486  loss:  0.20567508041858673\n",
      "epoch:  487  loss:  0.20554578304290771\n",
      "epoch:  488  loss:  0.2054271697998047\n",
      "epoch:  489  loss:  0.20529790222644806\n",
      "epoch:  490  loss:  0.20517916977405548\n",
      "epoch:  491  loss:  0.20504987239837646\n",
      "epoch:  492  loss:  0.20493102073669434\n",
      "epoch:  493  loss:  0.20480160415172577\n",
      "epoch:  494  loss:  0.20468273758888245\n",
      "epoch:  495  loss:  0.2045532763004303\n",
      "epoch:  496  loss:  0.2044343203306198\n",
      "epoch:  497  loss:  0.20430469512939453\n",
      "epoch:  498  loss:  0.20418576896190643\n",
      "epoch:  499  loss:  0.2040560245513916\n",
      "epoch:  500  loss:  0.2039370983839035\n",
      "epoch:  501  loss:  0.20380714535713196\n",
      "epoch:  502  loss:  0.20368823409080505\n",
      "epoch:  503  loss:  0.2035580575466156\n",
      "epoch:  504  loss:  0.20343931019306183\n",
      "epoch:  505  loss:  0.2033088654279709\n",
      "epoch:  506  loss:  0.2031901776790619\n",
      "epoch:  507  loss:  0.20305971801280975\n",
      "epoch:  508  loss:  0.20294074714183807\n",
      "epoch:  509  loss:  0.20281043648719788\n",
      "epoch:  510  loss:  0.20269112288951874\n",
      "epoch:  511  loss:  0.20256102085113525\n",
      "epoch:  512  loss:  0.20244130492210388\n",
      "epoch:  513  loss:  0.2023114413022995\n",
      "epoch:  514  loss:  0.20219135284423828\n",
      "epoch:  515  loss:  0.20206177234649658\n",
      "epoch:  516  loss:  0.20194117724895477\n",
      "epoch:  517  loss:  0.20181190967559814\n",
      "epoch:  518  loss:  0.20169083774089813\n",
      "epoch:  519  loss:  0.20156195759773254\n",
      "epoch:  520  loss:  0.20144033432006836\n",
      "epoch:  521  loss:  0.20131182670593262\n",
      "epoch:  522  loss:  0.20118960738182068\n",
      "epoch:  523  loss:  0.20106157660484314\n",
      "epoch:  524  loss:  0.20093877613544464\n",
      "epoch:  525  loss:  0.2008112221956253\n",
      "epoch:  526  loss:  0.2006877362728119\n",
      "epoch:  527  loss:  0.20056068897247314\n",
      "epoch:  528  loss:  0.2004365175962448\n",
      "epoch:  529  loss:  0.20030999183654785\n",
      "epoch:  530  loss:  0.20018510520458221\n",
      "epoch:  531  loss:  0.2000592201948166\n",
      "epoch:  532  loss:  0.19993352890014648\n",
      "epoch:  533  loss:  0.199808269739151\n",
      "epoch:  534  loss:  0.19968175888061523\n",
      "epoch:  535  loss:  0.19955718517303467\n",
      "epoch:  536  loss:  0.19942979514598846\n",
      "epoch:  537  loss:  0.1993059664964676\n",
      "epoch:  538  loss:  0.19917768239974976\n",
      "epoch:  539  loss:  0.19905570149421692\n",
      "epoch:  540  loss:  0.1989363133907318\n",
      "epoch:  541  loss:  0.19882391393184662\n",
      "epoch:  542  loss:  0.19870351254940033\n",
      "epoch:  543  loss:  0.19859196245670319\n",
      "epoch:  544  loss:  0.19847054779529572\n",
      "epoch:  545  loss:  0.1983599066734314\n",
      "epoch:  546  loss:  0.19823752343654633\n",
      "epoch:  547  loss:  0.1981276422739029\n",
      "epoch:  548  loss:  0.19800527393817902\n",
      "epoch:  549  loss:  0.19789424538612366\n",
      "epoch:  550  loss:  0.19777289032936096\n",
      "epoch:  551  loss:  0.19766069948673248\n",
      "epoch:  552  loss:  0.19754037261009216\n",
      "epoch:  553  loss:  0.19742697477340698\n",
      "epoch:  554  loss:  0.1973077356815338\n",
      "epoch:  555  loss:  0.19719305634498596\n",
      "epoch:  556  loss:  0.19707496464252472\n",
      "epoch:  557  loss:  0.1969589740037918\n",
      "epoch:  558  loss:  0.1968420445919037\n",
      "epoch:  559  loss:  0.19672471284866333\n",
      "epoch:  560  loss:  0.1966090202331543\n",
      "epoch:  561  loss:  0.19649025797843933\n",
      "epoch:  562  loss:  0.19637584686279297\n",
      "epoch:  563  loss:  0.1962556689977646\n",
      "epoch:  564  loss:  0.19614256918430328\n",
      "epoch:  565  loss:  0.19602088630199432\n",
      "epoch:  566  loss:  0.19590915739536285\n",
      "epoch:  567  loss:  0.19578595459461212\n",
      "epoch:  568  loss:  0.19567559659481049\n",
      "epoch:  569  loss:  0.195552259683609\n",
      "epoch:  570  loss:  0.19544050097465515\n",
      "epoch:  571  loss:  0.19531852006912231\n",
      "epoch:  572  loss:  0.19520512223243713\n",
      "epoch:  573  loss:  0.19508467614650726\n",
      "epoch:  574  loss:  0.1949695646762848\n",
      "epoch:  575  loss:  0.19485069811344147\n",
      "epoch:  576  loss:  0.1947338581085205\n",
      "epoch:  577  loss:  0.19461660087108612\n",
      "epoch:  578  loss:  0.1944979727268219\n",
      "epoch:  579  loss:  0.19438236951828003\n",
      "epoch:  580  loss:  0.19426193833351135\n",
      "epoch:  581  loss:  0.19414803385734558\n",
      "epoch:  582  loss:  0.1940256804227829\n",
      "epoch:  583  loss:  0.1939135491847992\n",
      "epoch:  584  loss:  0.19378961622714996\n",
      "epoch:  585  loss:  0.19367864727973938\n",
      "epoch:  586  loss:  0.19355495274066925\n",
      "epoch:  587  loss:  0.19344200193881989\n",
      "epoch:  588  loss:  0.19332019984722137\n",
      "epoch:  589  loss:  0.19320519268512726\n",
      "epoch:  590  loss:  0.19308531284332275\n",
      "epoch:  591  loss:  0.1929682046175003\n",
      "epoch:  592  loss:  0.1928502917289734\n",
      "epoch:  593  loss:  0.19273105263710022\n",
      "epoch:  594  loss:  0.19261515140533447\n",
      "epoch:  595  loss:  0.19249370694160461\n",
      "epoch:  596  loss:  0.1923799216747284\n",
      "epoch:  597  loss:  0.19225618243217468\n",
      "epoch:  598  loss:  0.19214724004268646\n",
      "epoch:  599  loss:  0.19202780723571777\n",
      "epoch:  600  loss:  0.19191128015518188\n",
      "epoch:  601  loss:  0.19178995490074158\n",
      "epoch:  602  loss:  0.19167573750019073\n",
      "epoch:  603  loss:  0.1915520429611206\n",
      "epoch:  604  loss:  0.1914444863796234\n",
      "epoch:  605  loss:  0.19132313132286072\n",
      "epoch:  606  loss:  0.19120636582374573\n",
      "epoch:  607  loss:  0.1910848319530487\n",
      "epoch:  608  loss:  0.19097039103507996\n",
      "epoch:  609  loss:  0.19084636867046356\n",
      "epoch:  610  loss:  0.19074049592018127\n",
      "epoch:  611  loss:  0.19061706960201263\n",
      "epoch:  612  loss:  0.19050030410289764\n",
      "epoch:  613  loss:  0.19037827849388123\n",
      "epoch:  614  loss:  0.19026406109333038\n",
      "epoch:  615  loss:  0.1901392638683319\n",
      "epoch:  616  loss:  0.19003523886203766\n",
      "epoch:  617  loss:  0.18990962207317352\n",
      "epoch:  618  loss:  0.18979331851005554\n",
      "epoch:  619  loss:  0.18967029452323914\n",
      "epoch:  620  loss:  0.18955665826797485\n",
      "epoch:  621  loss:  0.1894313544034958\n",
      "epoch:  622  loss:  0.18932093679904938\n",
      "epoch:  623  loss:  0.18920066952705383\n",
      "epoch:  624  loss:  0.18908526003360748\n",
      "epoch:  625  loss:  0.18896088004112244\n",
      "epoch:  626  loss:  0.18884828686714172\n",
      "epoch:  627  loss:  0.1887231171131134\n",
      "epoch:  628  loss:  0.18861903250217438\n",
      "epoch:  629  loss:  0.1884903460741043\n",
      "epoch:  630  loss:  0.18837614357471466\n",
      "epoch:  631  loss:  0.18825045228004456\n",
      "epoch:  632  loss:  0.1881384700536728\n",
      "epoch:  633  loss:  0.18801447749137878\n",
      "epoch:  634  loss:  0.1879076063632965\n",
      "epoch:  635  loss:  0.18777862191200256\n",
      "epoch:  636  loss:  0.1876661330461502\n",
      "epoch:  637  loss:  0.1875401884317398\n",
      "epoch:  638  loss:  0.18742606043815613\n",
      "epoch:  639  loss:  0.18730464577674866\n",
      "epoch:  640  loss:  0.1871948540210724\n",
      "epoch:  641  loss:  0.18706683814525604\n",
      "epoch:  642  loss:  0.18695364892482758\n",
      "epoch:  643  loss:  0.18682900071144104\n",
      "epoch:  644  loss:  0.18671229481697083\n",
      "epoch:  645  loss:  0.18659356236457825\n",
      "epoch:  646  loss:  0.18648068606853485\n",
      "epoch:  647  loss:  0.18635499477386475\n",
      "epoch:  648  loss:  0.18623895943164825\n",
      "epoch:  649  loss:  0.1861167699098587\n",
      "epoch:  650  loss:  0.1859971582889557\n",
      "epoch:  651  loss:  0.18588140606880188\n",
      "epoch:  652  loss:  0.18576505780220032\n",
      "epoch:  653  loss:  0.18564215302467346\n",
      "epoch:  654  loss:  0.1855229288339615\n",
      "epoch:  655  loss:  0.18540357053279877\n",
      "epoch:  656  loss:  0.18528056144714355\n",
      "epoch:  657  loss:  0.1851680874824524\n",
      "epoch:  658  loss:  0.18504813313484192\n",
      "epoch:  659  loss:  0.1849282681941986\n",
      "epoch:  660  loss:  0.1848054826259613\n",
      "epoch:  661  loss:  0.184689462184906\n",
      "epoch:  662  loss:  0.18456268310546875\n",
      "epoch:  663  loss:  0.18445047736167908\n",
      "epoch:  664  loss:  0.1843288689851761\n",
      "epoch:  665  loss:  0.18421758711338043\n",
      "epoch:  666  loss:  0.18408669531345367\n",
      "epoch:  667  loss:  0.18397440016269684\n",
      "epoch:  668  loss:  0.1838475465774536\n",
      "epoch:  669  loss:  0.18373100459575653\n",
      "epoch:  670  loss:  0.18361306190490723\n",
      "epoch:  671  loss:  0.18349775671958923\n",
      "epoch:  672  loss:  0.183370903134346\n",
      "epoch:  673  loss:  0.18325403332710266\n",
      "epoch:  674  loss:  0.18313142657279968\n",
      "epoch:  675  loss:  0.1830102503299713\n",
      "epoch:  676  loss:  0.18289609253406525\n",
      "epoch:  677  loss:  0.182776540517807\n",
      "epoch:  678  loss:  0.18265418708324432\n",
      "epoch:  679  loss:  0.18253235518932343\n",
      "epoch:  680  loss:  0.18241438269615173\n",
      "epoch:  681  loss:  0.18228809535503387\n",
      "epoch:  682  loss:  0.1821780502796173\n",
      "epoch:  683  loss:  0.18205393850803375\n",
      "epoch:  684  loss:  0.181936576962471\n",
      "epoch:  685  loss:  0.18180935084819794\n",
      "epoch:  686  loss:  0.18169642984867096\n",
      "epoch:  687  loss:  0.18156889081001282\n",
      "epoch:  688  loss:  0.1814519464969635\n",
      "epoch:  689  loss:  0.1813332885503769\n",
      "epoch:  690  loss:  0.18121738731861115\n",
      "epoch:  691  loss:  0.18109044432640076\n",
      "epoch:  692  loss:  0.18097227811813354\n",
      "epoch:  693  loss:  0.18084995448589325\n",
      "epoch:  694  loss:  0.18072697520256042\n",
      "epoch:  695  loss:  0.18061287701129913\n",
      "epoch:  696  loss:  0.18049201369285583\n",
      "epoch:  697  loss:  0.18037088215351105\n",
      "epoch:  698  loss:  0.18024644255638123\n",
      "epoch:  699  loss:  0.18013018369674683\n",
      "epoch:  700  loss:  0.18000219762325287\n",
      "epoch:  701  loss:  0.17988784611225128\n",
      "epoch:  702  loss:  0.17976535856723785\n",
      "epoch:  703  loss:  0.17965243756771088\n",
      "epoch:  704  loss:  0.1795225292444229\n",
      "epoch:  705  loss:  0.17940635979175568\n",
      "epoch:  706  loss:  0.17928150296211243\n",
      "epoch:  707  loss:  0.17916004359722137\n",
      "epoch:  708  loss:  0.17904262244701385\n",
      "epoch:  709  loss:  0.1789242923259735\n",
      "epoch:  710  loss:  0.17880114912986755\n",
      "epoch:  711  loss:  0.1786777228116989\n",
      "epoch:  712  loss:  0.17855986952781677\n",
      "epoch:  713  loss:  0.17843154072761536\n",
      "epoch:  714  loss:  0.17831791937351227\n",
      "epoch:  715  loss:  0.1781923472881317\n",
      "epoch:  716  loss:  0.1780817210674286\n",
      "epoch:  717  loss:  0.17795062065124512\n",
      "epoch:  718  loss:  0.1778346598148346\n",
      "epoch:  719  loss:  0.17770904302597046\n",
      "epoch:  720  loss:  0.1775873750448227\n",
      "epoch:  721  loss:  0.17746737599372864\n",
      "epoch:  722  loss:  0.17734193801879883\n",
      "epoch:  723  loss:  0.17722752690315247\n",
      "epoch:  724  loss:  0.17710332572460175\n",
      "epoch:  725  loss:  0.17698568105697632\n",
      "epoch:  726  loss:  0.17685697972774506\n",
      "epoch:  727  loss:  0.1767423450946808\n",
      "epoch:  728  loss:  0.17661504447460175\n",
      "epoch:  729  loss:  0.176495760679245\n",
      "epoch:  730  loss:  0.1763749122619629\n",
      "epoch:  731  loss:  0.17625734210014343\n",
      "epoch:  732  loss:  0.17613272368907928\n",
      "epoch:  733  loss:  0.17600910365581512\n",
      "epoch:  734  loss:  0.17589053511619568\n",
      "epoch:  735  loss:  0.17576158046722412\n",
      "epoch:  736  loss:  0.1756477653980255\n",
      "epoch:  737  loss:  0.17552334070205688\n",
      "epoch:  738  loss:  0.17540772259235382\n",
      "epoch:  739  loss:  0.1752787083387375\n",
      "epoch:  740  loss:  0.175161212682724\n",
      "epoch:  741  loss:  0.17503619194030762\n",
      "epoch:  742  loss:  0.17491234838962555\n",
      "epoch:  743  loss:  0.17480194568634033\n",
      "epoch:  744  loss:  0.17467451095581055\n",
      "epoch:  745  loss:  0.1745527982711792\n",
      "epoch:  746  loss:  0.17442534863948822\n",
      "epoch:  747  loss:  0.17431005835533142\n",
      "epoch:  748  loss:  0.1741807907819748\n",
      "epoch:  749  loss:  0.17406247556209564\n",
      "epoch:  750  loss:  0.17394483089447021\n",
      "epoch:  751  loss:  0.17382420599460602\n",
      "epoch:  752  loss:  0.173696830868721\n",
      "epoch:  753  loss:  0.17357462644577026\n",
      "epoch:  754  loss:  0.17345380783081055\n",
      "epoch:  755  loss:  0.173324853181839\n",
      "epoch:  756  loss:  0.1732138842344284\n",
      "epoch:  757  loss:  0.17308621108531952\n",
      "epoch:  758  loss:  0.17296931147575378\n",
      "epoch:  759  loss:  0.17283987998962402\n",
      "epoch:  760  loss:  0.17272241413593292\n",
      "epoch:  761  loss:  0.17259648442268372\n",
      "epoch:  762  loss:  0.17247219383716583\n",
      "epoch:  763  loss:  0.17235425114631653\n",
      "epoch:  764  loss:  0.17223313450813293\n",
      "epoch:  765  loss:  0.17211155593395233\n",
      "epoch:  766  loss:  0.17198264598846436\n",
      "epoch:  767  loss:  0.17186793684959412\n",
      "epoch:  768  loss:  0.17173825204372406\n",
      "epoch:  769  loss:  0.17161810398101807\n",
      "epoch:  770  loss:  0.17149457335472107\n",
      "epoch:  771  loss:  0.1713678240776062\n",
      "epoch:  772  loss:  0.1712527573108673\n",
      "epoch:  773  loss:  0.17112767696380615\n",
      "epoch:  774  loss:  0.1710089147090912\n",
      "epoch:  775  loss:  0.1708790510892868\n",
      "epoch:  776  loss:  0.1707625538110733\n",
      "epoch:  777  loss:  0.1706351339817047\n",
      "epoch:  778  loss:  0.17051129043102264\n",
      "epoch:  779  loss:  0.17040041089057922\n",
      "epoch:  780  loss:  0.1702713668346405\n",
      "epoch:  781  loss:  0.17014896869659424\n",
      "epoch:  782  loss:  0.17001979053020477\n",
      "epoch:  783  loss:  0.16990479826927185\n",
      "epoch:  784  loss:  0.16977477073669434\n",
      "epoch:  785  loss:  0.169653981924057\n",
      "epoch:  786  loss:  0.16953667998313904\n",
      "epoch:  787  loss:  0.16941368579864502\n",
      "epoch:  788  loss:  0.1692880541086197\n",
      "epoch:  789  loss:  0.16916166245937347\n",
      "epoch:  790  loss:  0.16904368996620178\n",
      "epoch:  791  loss:  0.16891345381736755\n",
      "epoch:  792  loss:  0.16879528760910034\n",
      "epoch:  793  loss:  0.16867174208164215\n",
      "epoch:  794  loss:  0.1685546189546585\n",
      "epoch:  795  loss:  0.1684263050556183\n",
      "epoch:  796  loss:  0.16830219328403473\n",
      "epoch:  797  loss:  0.16818168759346008\n",
      "epoch:  798  loss:  0.1680513471364975\n",
      "epoch:  799  loss:  0.167935311794281\n",
      "epoch:  800  loss:  0.16780665516853333\n",
      "epoch:  801  loss:  0.16768322885036469\n",
      "epoch:  802  loss:  0.16756370663642883\n",
      "epoch:  803  loss:  0.16744136810302734\n",
      "epoch:  804  loss:  0.16731886565685272\n",
      "epoch:  805  loss:  0.16718840599060059\n",
      "epoch:  806  loss:  0.16707393527030945\n",
      "epoch:  807  loss:  0.1669435054063797\n",
      "epoch:  808  loss:  0.16682079434394836\n",
      "epoch:  809  loss:  0.16670674085617065\n",
      "epoch:  810  loss:  0.16657932102680206\n",
      "epoch:  811  loss:  0.1664552390575409\n",
      "epoch:  812  loss:  0.1663258671760559\n",
      "epoch:  813  loss:  0.1662101447582245\n",
      "epoch:  814  loss:  0.16607949137687683\n",
      "epoch:  815  loss:  0.1659577637910843\n",
      "epoch:  816  loss:  0.16583800315856934\n",
      "epoch:  817  loss:  0.16571597754955292\n",
      "epoch:  818  loss:  0.1655907928943634\n",
      "epoch:  819  loss:  0.1654621660709381\n",
      "epoch:  820  loss:  0.1653454750776291\n",
      "epoch:  821  loss:  0.1652146875858307\n",
      "epoch:  822  loss:  0.1650935858488083\n",
      "epoch:  823  loss:  0.164969339966774\n",
      "epoch:  824  loss:  0.1648399382829666\n",
      "epoch:  825  loss:  0.1647256463766098\n",
      "epoch:  826  loss:  0.16459712386131287\n",
      "epoch:  827  loss:  0.164480060338974\n",
      "epoch:  828  loss:  0.16434922814369202\n",
      "epoch:  829  loss:  0.16422811150550842\n",
      "epoch:  830  loss:  0.16410362720489502\n",
      "epoch:  831  loss:  0.1639736145734787\n",
      "epoch:  832  loss:  0.1638651341199875\n",
      "epoch:  833  loss:  0.16373097896575928\n",
      "epoch:  834  loss:  0.16361401975154877\n",
      "epoch:  835  loss:  0.16348296403884888\n",
      "epoch:  836  loss:  0.16336148977279663\n",
      "epoch:  837  loss:  0.16323724389076233\n",
      "epoch:  838  loss:  0.16310656070709229\n",
      "epoch:  839  loss:  0.1629929095506668\n",
      "epoch:  840  loss:  0.16286364197731018\n",
      "epoch:  841  loss:  0.16274714469909668\n",
      "epoch:  842  loss:  0.16261611878871918\n",
      "epoch:  843  loss:  0.16249367594718933\n",
      "epoch:  844  loss:  0.16237014532089233\n",
      "epoch:  845  loss:  0.16223904490470886\n",
      "epoch:  846  loss:  0.16212353110313416\n",
      "epoch:  847  loss:  0.16199299693107605\n",
      "epoch:  848  loss:  0.1618681699037552\n",
      "epoch:  849  loss:  0.16175785660743713\n",
      "epoch:  850  loss:  0.16162478923797607\n",
      "epoch:  851  loss:  0.16150251030921936\n",
      "epoch:  852  loss:  0.16137126088142395\n",
      "epoch:  853  loss:  0.16125425696372986\n",
      "epoch:  854  loss:  0.1611250936985016\n",
      "epoch:  855  loss:  0.16099843382835388\n",
      "epoch:  856  loss:  0.16088330745697021\n",
      "epoch:  857  loss:  0.16075479984283447\n",
      "epoch:  858  loss:  0.16063420474529266\n",
      "epoch:  859  loss:  0.16050294041633606\n",
      "epoch:  860  loss:  0.16038380563259125\n",
      "epoch:  861  loss:  0.16025659441947937\n",
      "epoch:  862  loss:  0.16012772917747498\n",
      "epoch:  863  loss:  0.1600101739168167\n",
      "epoch:  864  loss:  0.15987884998321533\n",
      "epoch:  865  loss:  0.15975722670555115\n",
      "epoch:  866  loss:  0.15963399410247803\n",
      "epoch:  867  loss:  0.15951243042945862\n",
      "epoch:  868  loss:  0.1593875139951706\n",
      "epoch:  869  loss:  0.15925610065460205\n",
      "epoch:  870  loss:  0.15914086997509003\n",
      "epoch:  871  loss:  0.15900957584381104\n",
      "epoch:  872  loss:  0.15888431668281555\n",
      "epoch:  873  loss:  0.15876877307891846\n",
      "epoch:  874  loss:  0.15863993763923645\n",
      "epoch:  875  loss:  0.15851803123950958\n",
      "epoch:  876  loss:  0.1583864986896515\n",
      "epoch:  877  loss:  0.1582680195569992\n",
      "epoch:  878  loss:  0.15813986957073212\n",
      "epoch:  879  loss:  0.15801115334033966\n",
      "epoch:  880  loss:  0.1578931361436844\n",
      "epoch:  881  loss:  0.1577616184949875\n",
      "epoch:  882  loss:  0.15764017403125763\n",
      "epoch:  883  loss:  0.1575164496898651\n",
      "epoch:  884  loss:  0.15739431977272034\n",
      "epoch:  885  loss:  0.1572696417570114\n",
      "epoch:  886  loss:  0.15713810920715332\n",
      "epoch:  887  loss:  0.1570219099521637\n",
      "epoch:  888  loss:  0.15689125657081604\n",
      "epoch:  889  loss:  0.1567646712064743\n",
      "epoch:  890  loss:  0.15664975345134735\n",
      "epoch:  891  loss:  0.15651974081993103\n",
      "epoch:  892  loss:  0.15639907121658325\n",
      "epoch:  893  loss:  0.1562674194574356\n",
      "epoch:  894  loss:  0.1561470329761505\n",
      "epoch:  895  loss:  0.15602050721645355\n",
      "epoch:  896  loss:  0.15588943660259247\n",
      "epoch:  897  loss:  0.1557735949754715\n",
      "epoch:  898  loss:  0.15564188361167908\n",
      "epoch:  899  loss:  0.15551652014255524\n",
      "epoch:  900  loss:  0.15540723502635956\n",
      "epoch:  901  loss:  0.1552712768316269\n",
      "epoch:  902  loss:  0.1551494598388672\n",
      "epoch:  903  loss:  0.1550177037715912\n",
      "epoch:  904  loss:  0.15489813685417175\n",
      "epoch:  905  loss:  0.15477071702480316\n",
      "epoch:  906  loss:  0.15464018285274506\n",
      "epoch:  907  loss:  0.15452691912651062\n",
      "epoch:  908  loss:  0.15439476072788239\n",
      "epoch:  909  loss:  0.15427802503108978\n",
      "epoch:  910  loss:  0.15414634346961975\n",
      "epoch:  911  loss:  0.15402133762836456\n",
      "epoch:  912  loss:  0.1538991928100586\n",
      "epoch:  913  loss:  0.15376746654510498\n",
      "epoch:  914  loss:  0.15364781022071838\n",
      "epoch:  915  loss:  0.1535203754901886\n",
      "epoch:  916  loss:  0.1533896028995514\n",
      "epoch:  917  loss:  0.1532825231552124\n",
      "epoch:  918  loss:  0.15314391255378723\n",
      "epoch:  919  loss:  0.1530330628156662\n",
      "epoch:  920  loss:  0.15290987491607666\n",
      "epoch:  921  loss:  0.1527899205684662\n",
      "epoch:  922  loss:  0.15267696976661682\n",
      "epoch:  923  loss:  0.1525498926639557\n",
      "epoch:  924  loss:  0.1524425745010376\n",
      "epoch:  925  loss:  0.15231826901435852\n",
      "epoch:  926  loss:  0.152212455868721\n",
      "epoch:  927  loss:  0.15208664536476135\n",
      "epoch:  928  loss:  0.15196986496448517\n",
      "epoch:  929  loss:  0.1518547236919403\n",
      "epoch:  930  loss:  0.15173223614692688\n",
      "epoch:  931  loss:  0.15161697566509247\n",
      "epoch:  932  loss:  0.1515001356601715\n",
      "epoch:  933  loss:  0.15137521922588348\n",
      "epoch:  934  loss:  0.15127262473106384\n",
      "epoch:  935  loss:  0.15114334225654602\n",
      "epoch:  936  loss:  0.15101836621761322\n",
      "epoch:  937  loss:  0.15087741613388062\n",
      "epoch:  938  loss:  0.1507461816072464\n",
      "epoch:  939  loss:  0.15061506628990173\n",
      "epoch:  940  loss:  0.15048478543758392\n",
      "epoch:  941  loss:  0.15036986768245697\n",
      "epoch:  942  loss:  0.15024149417877197\n",
      "epoch:  943  loss:  0.15011721849441528\n",
      "epoch:  944  loss:  0.15000702440738678\n",
      "epoch:  945  loss:  0.14987732470035553\n",
      "epoch:  946  loss:  0.14975668489933014\n",
      "epoch:  947  loss:  0.14963094890117645\n",
      "epoch:  948  loss:  0.149508997797966\n",
      "epoch:  949  loss:  0.14938953518867493\n",
      "epoch:  950  loss:  0.14925551414489746\n",
      "epoch:  951  loss:  0.1491483747959137\n",
      "epoch:  952  loss:  0.14901213347911835\n",
      "epoch:  953  loss:  0.1488962471485138\n",
      "epoch:  954  loss:  0.14878298342227936\n",
      "epoch:  955  loss:  0.14865745604038239\n",
      "epoch:  956  loss:  0.1485314667224884\n",
      "epoch:  957  loss:  0.1484072357416153\n",
      "epoch:  958  loss:  0.1482870876789093\n",
      "epoch:  959  loss:  0.14816507697105408\n",
      "epoch:  960  loss:  0.14803610742092133\n",
      "epoch:  961  loss:  0.14792309701442719\n",
      "epoch:  962  loss:  0.14779500663280487\n",
      "epoch:  963  loss:  0.14768652617931366\n",
      "epoch:  964  loss:  0.1475554257631302\n",
      "epoch:  965  loss:  0.1474338173866272\n",
      "epoch:  966  loss:  0.14731600880622864\n",
      "epoch:  967  loss:  0.1471829116344452\n",
      "epoch:  968  loss:  0.1470739096403122\n",
      "epoch:  969  loss:  0.1469413936138153\n",
      "epoch:  970  loss:  0.14682398736476898\n",
      "epoch:  971  loss:  0.14670446515083313\n",
      "epoch:  972  loss:  0.14658573269844055\n",
      "epoch:  973  loss:  0.14646492898464203\n",
      "epoch:  974  loss:  0.14633958041667938\n",
      "epoch:  975  loss:  0.14621929824352264\n",
      "epoch:  976  loss:  0.1460985541343689\n",
      "epoch:  977  loss:  0.14597126841545105\n",
      "epoch:  978  loss:  0.14585766196250916\n",
      "epoch:  979  loss:  0.14573338627815247\n",
      "epoch:  980  loss:  0.14560575783252716\n",
      "epoch:  981  loss:  0.14549939334392548\n",
      "epoch:  982  loss:  0.14536724984645844\n",
      "epoch:  983  loss:  0.14525756239891052\n",
      "epoch:  984  loss:  0.14512480795383453\n",
      "epoch:  985  loss:  0.1450122743844986\n",
      "epoch:  986  loss:  0.1448877602815628\n",
      "epoch:  987  loss:  0.1447608917951584\n",
      "epoch:  988  loss:  0.14464960992336273\n",
      "epoch:  989  loss:  0.14452068507671356\n",
      "epoch:  990  loss:  0.14440181851387024\n",
      "epoch:  991  loss:  0.14428496360778809\n",
      "epoch:  992  loss:  0.14416679739952087\n",
      "epoch:  993  loss:  0.14404501020908356\n",
      "epoch:  994  loss:  0.14392265677452087\n",
      "epoch:  995  loss:  0.1438024789094925\n",
      "epoch:  996  loss:  0.14368291199207306\n",
      "epoch:  997  loss:  0.14355626702308655\n",
      "epoch:  998  loss:  0.14344361424446106\n",
      "epoch:  999  loss:  0.14332081377506256\n"
     ]
    }
   ],
   "source": [
    "#a simple nn with single hidden layer and one output\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#define input size, hidden layer size, output size, and batch size\n",
    "n_in, n_h, n_out, batch_size = 10, 5, 1, 10\n",
    "#create dummy input and target tensors\n",
    "x = torch.randn(batch_size, n_in)\n",
    "y = torch.tensor([[1.0],[0.0],[0.0],[1.0],[1.0],[1.0],[0.0],[0.0],[1.0],[1.0]])\n",
    "#create a sequential model with the help of in-built functions\n",
    "model = nn.Sequential(nn.Linear(n_in, n_h), nn.ReLU(),\n",
    "                      nn.Linear(n_h, n_out), nn.Sigmoid())\n",
    "#construct the loss function with the help of stochastic gradient descent optimizer\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "#implement\n",
    "for epoch in range(1000):\n",
    "    #forward pass: compute predicted y by passing x to the model\n",
    "    y_pred = model(x)\n",
    "    #compute and print loss\n",
    "    loss = criterion(y_pred, y)\n",
    "    print('epoch: ', epoch, ' loss: ', loss.item())\n",
    "    #zero gradients, perform a backward pass, and update the weights\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
